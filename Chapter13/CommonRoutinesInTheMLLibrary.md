## [П]|(РС]|(РП) Универсальные методы библиотеки ML

Эта глава содержит описание того, как работают алгоритмы машинного обучения. Будут рассмотрены удобные универсальные методы, описание которых можно найти в документации (.../opencv/docs/ref/opencvref_ml.htm), устанавливаемой вместе с OpenCV и/или в онлайн документации OpenCV Wiki (http://opencvlibrary.sourceforge.net). Данная под библиотека на момент написания книги находилась в активной разработке.

Все методы библиотеки ML (алгоритмы Haar classifier, Mahalanobis и K-means были реализованы до появления библиотеки ML и потому находятся в библиотеках *cv* и *cvcore*) написаны как классы C++, наследующиеся от класса *CvStatModel*, содержащий универсальные методы для всех алгоритмов. Эти методы перечислены в таблице 13-3. Стоит обратить внимание на то, что в *CvStatModel* реализованы две модели сохранения и загрузки данных: *save()* и *write()* для сохранения; load() и read() для загрузки. Для моделей машинного обучения необходимо использовать более простые *save()* и *load()*, которые по существу являются обертками более сложных функций *write()* и *read()* интерфейса, записывающего и читающего XML и YAML на и с диска. Реализация двух других наиболее важных функций, *predict()* и *train()*, зависит от алгоритма и будет рассматриваться чуть позже.

Таблица 13-3. Методы базового класса библиотеки ML

| **CvStatModel::Methods** | **Описание** |
| -- | -- |
| save( const char* filename, const char* name = 0 ) | Сохранение обученной модели в XML или YMAL. Метод используется для сохранения |
| load( const char* filename, const char* name = 0 ) | Вызов *clear()* с последующей загрузкой XML или YMAL модели. Метод используется для загрузки |
| clear() | Освобождение всей занимаемой памяти. Возможно повторное использование |
| bool train( —data points—, [flags] —responses—, [flags etc] ) | Функция обучения модели данных. Обучение специфично для каждого алгоритма и потому входные параметры различны |
| float predict( const CvMat* sample [,<prediction_params>] ) const | Функция используется после обучения для предсказания метки или значения новой обучаемой точки или точек |
| **Конструктор, Деструктор** |  |
| CvStatModel(); CvStatModel( const CvMat* train_data ... ); | Конструктор по умолчанию и конструктор, позволяющий создавать и обучать модель в одном кадре |
| CvStatModel::~CvStatModel(); | Деструктор |
| Поддерживаемые Write/Read (использовать save/load) |  |
| write( CvFileStorage* storage, const char* name ) | CvFileStorage - общая структура для записи на диск (обсуждалась в главе 3), расположенная в библиотеке *cvcore*. Вызывается из *save()* |
| read( CvFileStorage* storage, CvFileNode* node ) | CvFileStorage - общая структура для чтения с диска (обсуждалась в главе 3), расположенная в библиотеке *cvcore*. Вызывается из *load()* |

### Обучение

Прототип метода обучения:

```cpp
	bool CvStatModel::train(
		const CvMat*  train_data,
		[int tflag,] 				...,
		const CvMat*  responses, 	...,
		[const CvMat* var_idx,] 	...,
		[const CvMat* sample_idx,] 	...,
		[const CvMat* var_type,] 	...,
		[const CvMat* missing_mask,]
		<misc_training_alg_params> 	...
	);
```

Метод *train()* может принимать различные формы в зависимости от используемого алгоритма. Все алгоритмы принимают в качестве входных данных (для обучения) указатель на матрицу типа CvMat. Эта матрица должна быть типа 32FC1 (32-битной, вещественной, одноканальной). CvMat можно использовать и для многоканальных изображений, но алгоритмы машинного обучения могут работать только с одним каналом - т.е. только с двумерной матрицей чисел. Как правило, эта матрица организована в виде строк точек, где каждая "точка" представлена как вектор особенностей. Следовательно, столбцы содержат конкретные особенности для каждой точки, а все вместе точки образуют двумерную одноканальную матрицу для обучения. Таким образом типичная матрица данных состоит из (строка, столбец) = (точки, особенности). Вместе с тем некоторые алгоритмы могут обрабатывать транспонированную (обсуждалось ранее) матрицу. Для таких алгоритмов можно использовать параметр *tflag*, чтобы сообщить алгоритму о том, что точки находятся в столбцах, а не в строках. Это удобно, т.к. не нужно самостоятельно выполнять транспонирование. Когда алгоритм может обрабатывать данные, представленные обоими способами, необходимо использовать следующие флаги:

*tflag = CV_ROW_SAMPLE*

Это значит, что вектор особенностей хранится в строке (по умолчанию)

*tflag = CV_COL_SAMPLE*

Это значит, что вектор особенностей храниться в столбце

Может возникнуть вопрос: а что, если обучающий набор данных представлен не вещественными числами, а буквами алфавита или целыми числами, представляющие музыкальные ноты или названия растений? Ответ следующий: просто используйте 32-битные вещественные числа при заполнении *CvMat*. В случае с буквами, особенности или метки ASCII символов можно расценивать как вещественные числа при заполнении массива данных. Тоже самое относится и к целым числам. До тех пор, пока переход уникален, всё работает - однако, не стоит забывать, что некоторые методы чувствительны к широким различиям дисперсии между особенностями. В большинстве случаев, лучше нормализовать дисперсию особенностей, как было описано ранее. Лишь за исключением алгоритмов, основанных на деревьях (decision trees, random trees и boosting), которые поддерживают и недвусмысленные и упорядоченные входные переменные; все остальные алгоритмы OpenCV ML работают только с упорядоченными входами. Популярный метод создания упорядоченного входа для алгоритма также работает и с недвусмысленными данными, чтобы представить их в единичной системе счисления; например, если входная переменная цвета может иметь семь различных значений, то она может быть заменена на семь двоичных переменных, где одна и только одна из переменных может быть установлена в 1.

Параметр ответа может быть либо категорической меткой, такой как "ядовитый" или "неядовитый" в случае определения гриба, либо регрессионным значением (числом), таким как температура тела, измеренная при помощи термометра. Значение ответа или "метки", как правило, это одномерный вектор с одним значением на точку - за исключением нейронных сетей, которые могут иметь вектор ответов для каждой точки. Значения ответа могут иметь один из двух типов: для категоричных ответов тип может быть целым (*32SC1*); для регрессионных значений ответ может быть 32-битным вещественным (*32FC1*). При этом некоторые алгоритмы могут иметь проблемы только с классификационными проблемами, а некоторые только с регрессионными; а некоторые могут справиться и с первой, и со второй. В последнем случае, тип выходной переменной передается либо в виде отдельной переменной, либо как последний элемент вектора *var_type*, который может быть установлен следующим образом:

*CV_VAR_CATEGORICAL*

Это означает, что выходные значения являются раздельными классами меток

*CV_VAR_ORDERED (=CV_VAR_NUMERICAL)*

Это означает, что выходные значения упорядочены; т.е. различные значения можно сравнивать как числа, т.к. это регрессионная проблема

Типы входных переменных также можно задать при помощи *var_type*. Однако, алгоритмы регрессионного типа могут обрабатывать только упорядоченные входные переменные. Иногда возможно упорядочивание категоричных переменных до тех пор, пока порядок сохраняется последовательным, но иногда это может вызвать регрессионные затруднения, т.к. создается только видимость "упорядочивания" значений, которые будут иметь большой разброс, не имея при этом никакой физической основы для их упорядочивания.

Многие модели библиотеки ML могут быть обучены на выбранном подмножестве особенностей и/или выбранном простом подмножестве обучающего множества. Для упрощения данной ситуации для конечного пользователя, метод *train()*, как правило, включает в себя вектора *var_idx* и *sample_idx* в качестве параметров. По умолчанию можно использовать "все данные", установив значения этих параметров в NULL, но через *var_idx* можно передать только те переменные (особенности), которые вызывают интерес, так же как и через *sample_idx* можно передать только те точки, которые вызывают интерес. При помощи этих параметров собственно можно указать какие особенности и какие образцы точек необходимо использовать в процессе обучения. Оба вектора либо одноканальные целые (*CV_32SC1*) вектора - т.е. списки, индексация которых начинается с 0 - либо одноканальные 8-битные (*CV_8UC1*) маски активных переменных/образцов, где ненулевые значения означают активы. Параметр *sample_idx* особенно полезен в случае чтения данных порциями, при этом какая-то часть используется для обучения, а какая-то для тестирования, не нарушая при этом предназначения этих векторов.

Более того, некоторые алгоритмы могут обрабатывать недостающие измерения. Например, когда авторы работают с показателями хода производственного процесса, некоторые измерения особенностей могут пропасть навсегда во время перерыва на кофе. Иногда экспериментальные данные могут быть просто забыты, например, температура пациента за один день медицинского эксперимента. В этом случае, параметр *missing_mask* является 8-битной матрицей того же размера, что и *train_data*, и используемая для обозначения пропущенных значений (соответствующие ненулевым значениям маски). Некоторые алгоритмы не могут обработать недостающие значения, поэтому недостающие точки должны быть либо интерполированы пользователем перед обучением, либо исключены заранее. Другие алгоритмы, такие как decision tree и naïve Bayes, обрабатывают недостающие значения по-разному. В алгоритме decision tree используются альтернативные разделители (так называемые "суррогатные разделители" Breiman); алгоритм naïve Bayes выводит значения.

Как правило, ранее описанная модель очищается при помощи *clear()* перед запуском процесса обучения. Вместе с тем, некоторые алгоритмы могут (необязательно) обновлять обучаемые модели при поступлении нового набора для обучения, вместо запуска процесса с нуля.

### Прогнозирование

Метод *predict()* формирует параметр *var_idx*, который определяет какие особенности использовать в методе *train()*, для последующего извлечения только необходимых компонент из исходной выборки. Общий вид метода *predict()* следующий:

```cpp
	float CvStatMode::predict(
		const CvMat* sample
		[, <prediction_params>]
	) const;
```

Этот метод используется для прогнозирования ответа при поступлении нового вектора данных. При использовании классификатора, *predict()* возвращает метку класса. В случае с регрессией, этот метод возвращает числовое значение. При этом исходная выборка должна иметь столько же компонентов, как и параметр *train_data*, используемый в обучении. Дополнительный параметр *prediction_params* специфичен для конкретного алгоритма и позволяет обрабатывать недостающие особенности методов, базирующихся на основе деревьев. Суффикс *const* на конце функции говорит о том, что прогнозирование не влияет на внутреннее состояние модели, поэтому данный метод является потокобезопасным и может работать параллельно, что полезно в случае с веб-сервером, выполняющего поиск изображений для нескольких пользователей и роботов, необходимых для ускорения процесса сканирования сцены.

### Контролирование итераций обучения

Контролируемая итерации структура *CvTermCriteria*, которая используется некоторыми методами машинного обучения, уже обсуждалась ранее в предыдущих главах. В качестве напоминания данная структура приведена чуть ниже:

```cpp
	typedef struct CvTermCriteria {
		int 	type; 		/* CV_TERMCRIT_ITER и/или CV_TERMCRIT_EPS */
		int 	max_iter; 	/* максимальное число итераций */
		double 	epsilon; 	/* значения для остановки процесса */
	}
```

Целочисленное значение *max_iter* задает общее число итераций, которое алгоритм должен выполнить. Параметр *epsilon* задает пороговое значение, по достижении которого процесс прекращается. И наконец, параметр *type* сообщает о том, какой из этих двух критериев использовать, при этом возможно одновременное использование обоих критериев (CV_TERMCRIT_ITER | CV_TERMCRIT_EPS). Определения значений для *term_crit.type* следующие:

```cpp
#define CV_TERMCRIT_ITER 	1
#define CV_TERMCRIT_NUMBER 	CV_TERMCRIT_ITER
#define CV_TERMCRIT_EPS 	2
```

Теперь можно перейти к описанию алгоритмов, реализованных в OpenCV. Для начала будет рассмотрен наиболее часто используемый алгоритм *Mahalanobis distance*, а затем неконтролируемый алгоритм *K-means*; оба алгоритма можно найти в библиотеке *cxcore*. Потом будет рассмотрена библиотека ML, начиная с *normal Bayes classifier* и заканчивая алгоритмами, основанные на *decision-tree* (*decision trees*, *boosting*, *random trees* и *Haar cascade*). Для всех других алгоритмов будут представлены краткое описание и примеры использования.