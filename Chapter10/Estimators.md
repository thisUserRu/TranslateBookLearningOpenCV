## (П]|(РС)|(РП) Оценочная функция

Допустим, отслеживаются перемещения человека, гуляющего вдоль камеры. В каждом кадре происходит фиксация местоположения этого человека. Это может быть сделано любым, описанным ранее, способом, но в каждом отдельном случае ищется оценка положения человека в каждом кадре. Скорее всего, эта оценка будет не совсем точной. Причин для этого множество. Это может быть связано и с не точностью датчика, и от использования приближений на ранних этапах обработки, и с вопросами, связанные с сокрытиями или тенями, или с возможной сменой формы из-за того, что человек во время перемещений размахивает руками и ногами. Независимо от источника, ожидается, что изменения будут меняться несколько беспорядочно, а о "фактических" значениях может идти речь лишь при наличии идеализированного датчика. Можно представить все эти неточности как простое добавление шума к процессу отслеживания.

Необходимо иметь возможность оценки передвижений этого человека за счет максимально возможного использования сделанных измерений. Таким образом, совокупный эффект от всех измерений позволяет обнаруживать часть перемещений человека, не зависящих от шума. Ключевым дополнительным ингредиентом является *модель* перемещений человека. Например, можно смоделировать перемещение человека со следующим утверждением: "Человек попадает в кадр с одной стороны и перемещается вдоль кадра с постоянной скоростью". За счет такой модели можно определить не только местоположение человека, но и какие параметры модели поддерживают данное наблюдение.

Данная задача разбивается на два этапа (рисунок 10-18). Первый этап, как правило, именуется этапом предсказаний, в котором используется информация, полученная в прошлом, для улучшения модели с местоположением человека (или предмета). Второй этап, этап коррекции, производит измерение с последующим сопоставлением с предсказанными ранее измерениями.

![Рисунок 10-18 не найден](Images/Pic_10_18.jpg)

Рисунок 10-18. Двухэтапный цикл оценки: предсказание на основе предыдущих данных с последующим применением новых измерений

Принцип действия задачи двухэтапной оценки соответствует оценке наиболее популярного метода, использующего *фильтр Kalman*. В дополнение к этому методу, есть ещё один наиболее важный метод, *алгоритм condensation*, реализующий широкий класс методов, известных как фильтры частиц. Основное различие между фильтром Kalman и алгоритмом condensation сводится к описанию плотности вероятного состояния. Данное различие будет более подробно рассмотрено в следующих разделах.

### Фильтр Kalman

!!! Нумерацию формул подправить !!!

С момента первых упоминаний (1960 г.) о фильтре Kalman его значение заметно возросло. Основная идея фильтра Kalman заключается в том, что при строгом, но разумно, наборе предположений можно – при учете истории изменений системы - построить модель состояний системы, которая максимизирует *posterior* вероятность предыдущих изменений. Более подробную информацию можно найти в работах Welsh и Bishop. Кроме того, можно максимизировать *posterior* (это академический жаргон, означающий "взгляд в прошлое"; таким образом, когда говорят, что такое то распределение "максимизирует posteriori вероятность", то это можно трактовать как "что на самом деле произошло") вероятность без ведения длинной истории предыдущих изменений. Вместо этого происходит многократное обновление модели состояний системы и сохранение этой модели для последующей итерации. Это значительно упрощает вычислительную часть этого метода. 

Перед тем, как переходить к деталям, необходимо уделить немного времени на обсуждение предположений. Имеется три важных предположения, необходимые для теоретического истолкования фильтра Kalman: (1) моделируемая система линейна, (2) шум – это измерения, сделанные вне "белого", и (3) этот шум имеет Gaussian природу. Первое предположение означает, что состояние системы в момент времени *k* может быть смоделирована как некая матрица, помноженная на состояние в момент времени *k - 1*. Остальные предположения означают, что шум не коррелируется во времени, а его амплитуда может быть точно смоделирована только при помощи среднего значения и ковариации (т.е. шум полностью можно описать при помощи первых и вторых моментов). Эти предположения могут показаться ограниченными, однако, на самом деле они охватывают множество случаев (единственное, что стоит учесть, так это то, что если начальное состояние (например) имеет шансы 50×50, то потребуется использовать что-то более сложное, чем только фильтр Kalman).

Что же означает "максимизация posteriori вероятности предыдущих изменений"? Это означает, что новая модель строиться после проведения измерений – с учетом неопределенности предыдущей модели и нового значения - модели, обладающей лучшей вероятностью быть правильной. Это означает, что фильтр Kalman, с учетом трех предположений, является лучшим способом объединения данных из различных источников или из одного, но с данными полученными в разные моменты времени. 

При наличии уже знакомой информации происходит получение новой информации, с последующим изменением уже знакомой информации, основываясь на надежности старой и новой информации в соответствии с взвешенным сочетанием старого и нового. 

Далее будет более подробно рассмотрен принцип работы фильтра на примере одномерного движения. Его можно пропустить и перейти к следующему разделу.

**Немного математики Kalman**

Так в чем же суть фильтра Kalman? - *сплав информации*. Например, необходимо узнать, где некая точка находиться на линии (одномерный сценарий). В результате наличия шума имеется два ненадежных (в Гауссовом смысле) места: ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg). Гауссова неопределенность имеет значения ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg) в совокупности со стандартными отклонениями ![Рисунок 10- не найден](Images/Frml_10_.jpg) и ![Рисунок 10- не найден](Images/Frml_10_.jpg). Стандартные отклонения – это выражение неопределенности относительно того, насколько хороши измерения. Распределение вероятности в зависимости от локаций именуется *Гауссовым распределением*:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

При наличии двух таких измерений, каждое с Гауссовым распределением вероятности, можно ожидать, что плотность вероятности при некотором значении *x* и учете обоих измерений будет пропорциональна ![Рисунок 10- не найден](Images/Frml_10_.jpg). Оказывается, этот результат является ещё одним распределением гаусса, для которого можно вычислить среднее значение и стандартное отклонение следующим образом: при условии, что 

![Рисунок 10- не найден](Images/Frml_10_.jpg)

а также при условии, что распределение гаусса имеет максимум в среднем значение, можно найти это среднее значение просто вычислив производную *p(x)* по *x*. Производная функции в точке максимума равна 0:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Т.к функция распределения вероятности *p(x)* никогда не равна 0, то выражение в скобках должно быть равно 0. Решение данного уравнения для *x* дает очень важное соотношение:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Это новое среднее значение ![Рисунок 10- не найден](Images/Frml_10_.jpg) является просто взвешенной суммой двух измерений средних, где взвешивание определяется относительно неопределенности двух измерений. При этом, например, если неопределенность ![Рисунок 10- не найден](Images/Frml_10_.jpg) второго измерения особенно велика, то новое среднее по существу будет таким же, как среднее ![Рисунок 10- не найден](Images/Frml_10_.jpg) для ранее определенного измерения.

После подставления нового среденего значения ![Рисунок 10- не найден](Images/Frml_10_.jpg) в выражение ![Рисунок 10- не найден](Images/Frml_10_.jpg) и существенных преобразований неопределенность ![Рисунок 10- не найден](Images/Frml_10_.jpg) можно определить следующим образом:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Но что означает полученная величина? На самом деле многое. А именно: при выполнении нового измерения с новыми значениями среднего и неопределенности, можно объединить эти значения с уже имеющимися значениями среднего и неопределенности для получения нового состояния, которое характеризуется ещё более новыми средним значением и неопределенностью.

Свойство, что два гауссова измерения в сочетании эквивалентны одному гауссовому измерению (с вычисленными средним и неопределенностью), является наиболее важным. Это означает, что при наличии измерения *M* можно объединить первые два измерения, третье объединить с объединением первых двух, четвертое объединить с объединением первых трех и т.д. Это именно то, что происходит при слежении в компьютерном зрении; после получения одной меры следует получение следующей, а за ней следйющей и т.д.

Приняв измерерния ![Рисунок 10- не найден](Images/Frml_10_.jpg) за временные шаги, можно вычислить текущее состояние оценки ![Рисунок 10- не найден](Images/Frml_10_.jpg) следующим образом. На первом шаге имеется только одно измерение ![Рисунок 10- не найден](Images/Frml_10_.jpg) и его неопределенность ![Рисунок 10- не найден](Images/Frml_10_.jpg). Подставляя эти значения в оптимальное уравнение оценки получается следующее уравнение:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Преобразование данной формулы дает следующюю полезную формулу:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Прежде, чем беспокоиться о полезости этой формулы, необходимо также вычислить аналогичное уравнение для ![Рисунок 10- не найден](Images/Frml_10_.jpg). В о первых после подстановки ![Рисунок 10- не найден](Images/Frml_10_.jpg) получается следующая формула:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

В результате преобразований, схожых с теми, что были сделаны для ![Рисунок 10- не найден](Images/Frml_10_.jpg), получается итерационное уравнение для оценки дисперсии нового измерения:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

В таком виде данные уравнения позволяют точно отделить "старую" информацию (то, что было известно ранее как новое измерение) от "новой" информации (последенее измерение). Новая информация ![Рисунок 10- не найден](Images/Frml_10_.jpg), получаемая на втором шаге, именуется новейшей. Коэффициент оптимального итерационного обновления выглядит следующим образом:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

Этот коэффициент более известен как коэффициент *обновления прироста*. После применения данного коэффициента, ранее рассмотренные формулы преобразуются в удобные рекурсивные формулы:

![Рисунок 10- не найден](Images/Frml_10_.jpg)

![Рисунок 10- не найден](Images/Frml_10_.jpg)

В литературе, когда речь заходит о фильтре Kalman в рамках генеральной выборки измерений второq шаг обозначается k, а первый k - 1.

**Динамичные системы**

